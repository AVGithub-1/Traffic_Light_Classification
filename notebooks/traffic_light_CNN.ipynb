{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Steps: \n",
    "# try the current configuration for hyperparameter tuning, and use minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import tensorflow as tf\n",
    "#import tensorflow_models as tfm\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, losses, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "#from tensorflow_models.vision.heads import RPNHead\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "import tqdm as tqdm\n",
    "import scipy\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\akhpv\\OneDrive\\Documents\\Machine_Learning_Practice\\LISA_Dataset\\traffic_light_CNN.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m add_to_df\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                 filename \u001b[39m=\u001b[39m fix_filename(add_to_df\u001b[39m.\u001b[39mloc[i,\u001b[39m'\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                 add_to_df\u001b[39m.\u001b[39;49mloc[i,\u001b[39m'\u001b[39;49m\u001b[39mFilename\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m filename\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             df_box \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_box, add_to_df], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m df_box\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdf_img.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\akhpv\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    884\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 885\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\akhpv\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\indexing.py:1893\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1892\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1893\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1894\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1895\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\akhpv\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\indexing.py:1986\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1983\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1984\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m   1985\u001b[0m     \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m ilocs:\n\u001b[1;32m-> 1986\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_single_column(loc, value, pi)\n",
      "File \u001b[1;32mc:\\Users\\akhpv\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\indexing.py:2095\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   2091\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39misetitem(loc, value)\n\u001b[0;32m   2092\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2093\u001b[0m     \u001b[39m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m     \u001b[39m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[1;32m-> 2095\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcolumn_setitem(loc, plane_indexer, value)\n\u001b[0;32m   2097\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\akhpv\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1309\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[1;34m(self, loc, idx, value, inplace_only)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1308\u001b[0m     new_mgr \u001b[39m=\u001b[39m col_mgr\u001b[39m.\u001b[39msetitem((idx,), value)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miset(loc, new_mgr\u001b[39m.\u001b[39;49m_block\u001b[39m.\u001b[39;49mvalues, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\akhpv\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1112\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace, refs)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39m# Accessing public blknos ensures the public versions are initialized\u001b[39;00m\n\u001b[0;32m   1111\u001b[0m blknos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblknos[loc]\n\u001b[1;32m-> 1112\u001b[0m blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblklocs[loc]\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m   1114\u001b[0m unfit_mgr_locs \u001b[39m=\u001b[39m []\n\u001b[0;32m   1115\u001b[0m unfit_val_locs \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fix_filename(filename):\n",
    "    fil1, fil2 = filename.split('/')\n",
    "    if 'daySequence1' in filename:\n",
    "        return 'daySequence1/daySequence1/frames/' + fil2\n",
    "    elif 'daySequence2' in filename:\n",
    "        return 'daySequence2/daySequence2/frames/' + fil2\n",
    "    elif 'dayTraining' in filename:\n",
    "        clip, c = fil2.split(\"-\", maxsplit=1)\n",
    "        return 'dayTrain/dayTrain/' + clip + \"/frames/\" + fil2\n",
    "    elif 'nightSequence1' in filename:\n",
    "        return 'nightSequence1/nightSequence1/frames/' + fil2\n",
    "    elif 'nightSequence2' in filename:\n",
    "        return 'nightSequence2/nightSequence2/frames/' + fil2\n",
    "    elif 'nightTraining' in filename:\n",
    "        clip, c = fil2.split(\"-\", maxsplit=1)\n",
    "        return 'nightTrain/nightTrain/' + clip + \"/frames/\" + fil2\n",
    "\n",
    "#import the box annotation data\n",
    "df_box = pd.DataFrame()\n",
    "for dirname, _, filenames in os.walk('C:/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset'):\n",
    "    for filename in filenames:\n",
    "        if \"BOX.csv\" in filename:\n",
    "            add_to_df = pd.read_csv(os.path.join(dirname,filename), sep=';')\n",
    "            add_to_df = add_to_df.drop(add_to_df.columns[-4:], axis=1)\n",
    "            for i, row in add_to_df.iterrows():\n",
    "                filename = fix_filename(add_to_df.loc[i,'Filename'])\n",
    "                add_to_df.loc[i,'Filename'] = filename\n",
    "\n",
    "                \n",
    "            df_box = pd.concat([df_box, add_to_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "df_box.to_csv('df_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Annotation tag', 'Upper left corner X',\n",
       "       'Upper left corner Y', 'Lower right corner X', 'Lower right corner Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you're using \n",
    "df_box = pd.read_csv('df_img.csv')\n",
    "df_box.columns\n",
    "\n",
    "df_box = df_box.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "df_box.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Annotation tag</th>\n",
       "      <th>Upper left corner X</th>\n",
       "      <th>Upper left corner Y</th>\n",
       "      <th>Lower right corner X</th>\n",
       "      <th>Lower right corner Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daySequence1/daySequence1/frames/daySequence1-...</td>\n",
       "      <td>stop</td>\n",
       "      <td>706</td>\n",
       "      <td>478</td>\n",
       "      <td>718</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daySequence1/daySequence1/frames/daySequence1-...</td>\n",
       "      <td>stop</td>\n",
       "      <td>705</td>\n",
       "      <td>475</td>\n",
       "      <td>720</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>daySequence1/daySequence1/frames/daySequence1-...</td>\n",
       "      <td>stop</td>\n",
       "      <td>707</td>\n",
       "      <td>476</td>\n",
       "      <td>719</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daySequence1/daySequence1/frames/daySequence1-...</td>\n",
       "      <td>stop</td>\n",
       "      <td>708</td>\n",
       "      <td>474</td>\n",
       "      <td>720</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daySequence1/daySequence1/frames/daySequence1-...</td>\n",
       "      <td>stop</td>\n",
       "      <td>707</td>\n",
       "      <td>470</td>\n",
       "      <td>722</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112365</th>\n",
       "      <td>nightTrain/nightTrain/nightClip1/frames/nightC...</td>\n",
       "      <td>go</td>\n",
       "      <td>872</td>\n",
       "      <td>17</td>\n",
       "      <td>958</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112366</th>\n",
       "      <td>nightTrain/nightTrain/nightClip1/frames/nightC...</td>\n",
       "      <td>go</td>\n",
       "      <td>938</td>\n",
       "      <td>5</td>\n",
       "      <td>1028</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112367</th>\n",
       "      <td>nightTrain/nightTrain/nightClip1/frames/nightC...</td>\n",
       "      <td>go</td>\n",
       "      <td>1006</td>\n",
       "      <td>6</td>\n",
       "      <td>1094</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112368</th>\n",
       "      <td>nightTrain/nightTrain/nightClip1/frames/nightC...</td>\n",
       "      <td>go</td>\n",
       "      <td>1081</td>\n",
       "      <td>0</td>\n",
       "      <td>1171</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112369</th>\n",
       "      <td>nightTrain/nightTrain/nightClip1/frames/nightC...</td>\n",
       "      <td>go</td>\n",
       "      <td>1158</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112370 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Filename Annotation tag  \\\n",
       "0       daySequence1/daySequence1/frames/daySequence1-...           stop   \n",
       "1       daySequence1/daySequence1/frames/daySequence1-...           stop   \n",
       "2       daySequence1/daySequence1/frames/daySequence1-...           stop   \n",
       "3       daySequence1/daySequence1/frames/daySequence1-...           stop   \n",
       "4       daySequence1/daySequence1/frames/daySequence1-...           stop   \n",
       "...                                                   ...            ...   \n",
       "112365  nightTrain/nightTrain/nightClip1/frames/nightC...             go   \n",
       "112366  nightTrain/nightTrain/nightClip1/frames/nightC...             go   \n",
       "112367  nightTrain/nightTrain/nightClip1/frames/nightC...             go   \n",
       "112368  nightTrain/nightTrain/nightClip1/frames/nightC...             go   \n",
       "112369  nightTrain/nightTrain/nightClip1/frames/nightC...             go   \n",
       "\n",
       "        Upper left corner X  Upper left corner Y  Lower right corner X  \\\n",
       "0                       706                  478                   718   \n",
       "1                       705                  475                   720   \n",
       "2                       707                  476                   719   \n",
       "3                       708                  474                   720   \n",
       "4                       707                  470                   722   \n",
       "...                     ...                  ...                   ...   \n",
       "112365                  872                   17                   958   \n",
       "112366                  938                    5                  1028   \n",
       "112367                 1006                    6                  1094   \n",
       "112368                 1081                    0                  1171   \n",
       "112369                 1158                    0                  1246   \n",
       "\n",
       "        Lower right corner Y  \n",
       "0                        500  \n",
       "1                        497  \n",
       "2                        494  \n",
       "3                        492  \n",
       "4                        492  \n",
       "...                      ...  \n",
       "112365                   143  \n",
       "112366                   131  \n",
       "112367                   117  \n",
       "112368                   110  \n",
       "112369                   101  \n",
       "\n",
       "[112370 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation tag\n",
       "go             48892\n",
       "stop           44730\n",
       "stopLeft       13048\n",
       "warning         2669\n",
       "goLeft          2476\n",
       "warningLeft      350\n",
       "goForward        205\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_box['Annotation tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annotation tag\n",
       "go          13048\n",
       "stop        13048\n",
       "stopLeft    13048\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tag in ['warning', 'goLeft', 'warningLeft', 'goForward']:\n",
    "    df_box = df_box.drop(df_box[df_box['Annotation tag'] == tag].index)\n",
    "\n",
    "# Count the occurrences of each value in the 'Category' column\n",
    "category_counts = df_box['Annotation tag'].value_counts()\n",
    "\n",
    "# Determine the minimum count of occurrences for each category\n",
    "min_count = category_counts.min() \n",
    "\n",
    "# Initialize an empty DataFrame to store the sampled rows\n",
    "sampled_df = pd.DataFrame(columns=df_box.columns)\n",
    "\n",
    "# Sample an equal number of rows for each category\n",
    "for category in category_counts.index:\n",
    "    category_samples = df_box[df_box['Annotation tag'] == category].sample(min_count)\n",
    "    sampled_df = pd.concat([sampled_df, category_samples], ignore_index=True)\n",
    "\n",
    "sampled_df['Annotation tag'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['label'] = 0\n",
    "\n",
    "\n",
    "for i,row in sampled_df.iterrows():\n",
    "    if sampled_df.loc[i, 'Annotation tag'] == 'stop':\n",
    "        sampled_df.loc[i, 'label'] = 0\n",
    "        \n",
    "    elif sampled_df.loc[i, 'Annotation tag'] == 'stopLeft':\n",
    "        sampled_df.loc[i, 'label'] = 1\n",
    "\n",
    "    elif sampled_df.loc[i, 'Annotation tag'] == 'go':\n",
    "        sampled_df.loc[i, 'label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sampled_df.sample(frac = 1, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv('sampled_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to get the sampled_df automatically:\n",
    "sampled_df = pd.read_csv('sampled_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split sample data into training and testing dataframe\n",
    "\n",
    "split_point = int(len(sampled_df)*0.8)\n",
    "sampled_df_train = sampled_df.loc[0:split_point]\n",
    "sampled_df_test = sampled_df.loc[split_point: len(sampled_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25053 validated image filenames belonging to 3 classes.\n",
      "i\n",
      "Found 6263 validated image filenames belonging to 3 classes.\n",
      "j\n",
      "Found 7829 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset'\n",
    "\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator()\n",
    "#maybe add validation, but I gotta learn what it is first\n",
    "\n",
    "train_set = train_datagen.flow_from_dataframe(dataframe = sampled_df_train, x_col='Filename', y_col = 'Annotation tag', target_size=(192,256), subset=\"training\", class_mode=\"sparse\")\n",
    "print('i')\n",
    "val_set = train_datagen.flow_from_dataframe(dataframe = sampled_df_train, x_col='Filename', y_col = 'Annotation tag', target_size=(192,256), subset=\"validation\", class_mode=\"sparse\")\n",
    "print('j')\n",
    "test_set = test_datagen.flow_from_dataframe(dataframe = sampled_df_test, x_col='Filename', y_col = 'Annotation tag', target_size=(192,256), class_mode=\"sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with OpenCV, we can resize each image in our dataset and then get the RGB values of each pixel\n",
    "#This is an example of that, with an image to show how the image itself looks\n",
    "#resized images will be of shape 64x64\n",
    "\n",
    "def print_img(filename):\n",
    "    img = cv.imread(filename)\n",
    "    print(img.shape)\n",
    "    resize = cv.resize(img, (256, 256))\n",
    "\n",
    "    print(resize.shape)\n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    resize = cv.cvtColor(resize, cv.COLOR_BGR2RGB)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax1.imshow(img)\n",
    "    ax2.imshow(resize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Model and Train/Test It\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "  model = models.Sequential()\n",
    "\n",
    "  #hyperparameter for number of layers\n",
    "  #hyperparameter for filters in each layer\n",
    "  #hyperparameter for window size in each conv2D layer\n",
    "\n",
    "  hp_num_conv = 2\n",
    "\n",
    "  hp_layers_list = []\n",
    "  for i in range(hp_num_conv):\n",
    "    hp_layer = hp.Choice(name = 'layer_'+str(i), values = [32, 64])\n",
    "    hp_layers_list.append(hp_layer)\n",
    "\n",
    "\n",
    "  for i in hp_layers_list:\n",
    "    model.add(layers.Conv2D(filters = i, kernel_size = (3, 3), activation='relu', input_shape=(192,256, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=128, max_value=512, step=128)\n",
    "  model.add(layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(layers.Dense(3))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01 or 0.001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3])\n",
    "\n",
    "  model.compile(optimizer=optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\hyperparam_tuning_results\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_1 = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     factor=3,\n",
    "                     project_name='hyperparam_tuning_results')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPU devices:\", physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "layer_0 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
      "layer_1 (Choice)\n",
      "{'default': 32, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 128, 'sampling': 'linear'}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner_1.search_space_summary(extended=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    tuner_1.search(train_set, batch_size = 32, validation_data=val_set, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 512 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner_1.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_0': 32, 'layer_1': 64, 'units': 512, 'learning_rate': 0.001, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 4, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "best_hps_dict = best_hps.values\n",
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps['layer_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = models.Sequential()\n",
    "final_model.add(layers.Conv2D(filters = best_hps['layer_0'], kernel_size = (3, 3), activation='relu', input_shape=(192,256, 3)))\n",
    "final_model.add(layers.MaxPooling2D((2, 2)))\n",
    "final_model.add(layers.Conv2D(filters = best_hps['layer_1'], kernel_size = (3, 3), activation='relu', input_shape=(192,256, 3)))\n",
    "final_model.add(layers.MaxPooling2D((2, 2)))\n",
    "final_model.add(layers.Flatten())\n",
    "final_model.add(layers.Dense(units=best_hps['units'], activation='relu'))\n",
    "final_model.add(layers.Dense(3))\n",
    "\n",
    "final_model.compile(optimizer=optimizers.Adam(learning_rate=best_hps['learning_rate']),\n",
    "                loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "783/783 [==============================] - 196s 247ms/step - loss: 26.6421 - accuracy: 0.7118 - val_loss: 0.5409 - val_accuracy: 0.7709\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 158s 201ms/step - loss: 0.4673 - accuracy: 0.7884 - val_loss: 0.5003 - val_accuracy: 0.7747\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 160s 204ms/step - loss: 0.4104 - accuracy: 0.8057 - val_loss: 0.5138 - val_accuracy: 0.7642\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 158s 202ms/step - loss: 0.3841 - accuracy: 0.8114 - val_loss: 0.5233 - val_accuracy: 0.7678\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 157s 200ms/step - loss: 0.3668 - accuracy: 0.8194 - val_loss: 0.5429 - val_accuracy: 0.7573\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 159s 203ms/step - loss: 0.3567 - accuracy: 0.8231 - val_loss: 0.5662 - val_accuracy: 0.7719\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 156s 199ms/step - loss: 0.3455 - accuracy: 0.8260 - val_loss: 0.5512 - val_accuracy: 0.7433\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    final_model.fit(train_set, epochs = 10, callbacks = stop_early, validation_data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\akhpv\\OneDrive\\Documents\\Machine_Learning_Practice\\LISA_Dataset\\traffic_light_CNN.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(final_model\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m], label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/akhpv/OneDrive/Documents/Machine_Learning_Practice/LISA_Dataset/traffic_light_CNN.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plt.plot(final_model.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
